# Scaled Impact Assessment: Multi-Dimensional Evaluation Framework

## Overview
This framework offers a structured way to evaluate potential outcomes across multiple dimensions before committing to a course of action. It was developed after a series of village projects revealed that risks, benefits, and tradeoffs were often considered in isolation. By scoring impacts in parallel and comparing them through a shared lens, the council can surface hidden dependencies, coordinate mitigations, and make more transparent decisions about complex initiatives.

## Framework Components
1. **Impact Dimensions:** Core dimensions include safety, privacy, ethics, practicality, environmental stewardship, economic sustainability, and community cohesion. Each decision team is encouraged to tailor the list—for example, the Park Cleanup task force added “habitat disruption,” while the AI forecasting group created a separate “algorithmic bias” lens.
2. **Severity Scales:** Each dimension uses a five-point magnitude scale ranging from negligible to catastrophic. Scores reference agreed-upon exemplars drawn from past village events, e.g., “Moderate safety impact” equates to injuries requiring first aid, while “Severe privacy impact” reflects unauthorized disclosure of personal health information.
3. **Probability Assessment:** Likelihood scores are estimated on a five-tier probability ladder (rare, unlikely, possible, likely, almost certain). Teams leverage historical data, expert judgment, and scenario stress-testing to anchor the estimates; for the market-day crowd management plan we supplemented anecdotal reports with two seasons of foot-traffic counts.
4. **Composite Scoring:** Weighted averages combine severity and probability across dimensions. Default weights (safety 25%, ethics 20%, privacy 15%, practicality 15%, environmental 15%, community cohesion 10%) were set after a full council review but can be adjusted when a project clearly elevates one dimension. The AI forecasting review doubled the ethics weight to 40% to reflect community sensitivities.
5. **Threshold Definitions:** Action thresholds translate composite scores into decision triggers. For instance, any dimension scoring “Severe” or “Almost Certain” automatically escalates to council debate. Composite scores above 3.2 require a mitigation plan before implementation, while scores below 2.0 can proceed with routine monitoring.

## Implementation Process
1. **Dimension Selection:** Convene stakeholders to identify relevant impact dimensions. During the riverbank restoration effort, fishers, teachers, elders, and youth representatives co-created a dimension list that balanced ecological concerns with accessibility for school groups.
2. **Scenario Mapping:** Outline plausible outcomes, both positive and negative. The Four-Pillar Guardrails assessment mapped scenarios ranging from “enhanced community safety” to “over-policing of public spaces,” ensuring benefits and harms were on equal footing.
3. **Impact Evaluation:** Score severity and likelihood for each dimension-scenario pair. Teams document rationales, cite data sources, and flag uncertainties. In the Park Cleanup analysis, we logged differing expert opinions on soil erosion to revisit once more samples were collected.
4. **Risk Calculation:** Apply weights and thresholds to compute composite risk profiles. Calculations are performed in the shared scoring worksheet so future teams can audit inputs. The AI forecasting ethics review used sensitivity analysis to show how results shifted when the ethics weight varied between 30% and 50%.
5. **Mitigation Planning:** Design responses proportional to identified risks. For high-severity safety risks in the night market lighting project, the team introduced phased rollouts, additional training, and contingency funding. Mitigations are recorded alongside the original scores to track effectiveness during post-implementation reviews.

## Practical Applications
- **Four-Pillar Guardrails Assessment:** Assessed surveillance camera deployment by weighing safety gains against privacy and community trust drawbacks. The matrix highlighted that without data retention limits, privacy severity jumped to “Severe,” prompting policy revisions before installation.
- **Park Cleanup Risk Analysis:** Evaluated volunteer cleanup of the north meadow. Safety risks (sharp debris, uneven terrain) and environmental impacts (habitat disturbance) scored high until mitigations—protective gear, staggered work zones, wildlife quiet hours—lowered the composite score below the 3.2 action threshold.
- **AI Forecasting Ethics Review:** Reviewed predictive analytics for crop yields. Ethical concerns around data consent and algorithmic bias scored high severity. The assessment led to phased consent collection, inclusion of agrarian cooperative oversight, and a charter for periodic bias audits.

## Visual Tools
- **Impact Heat Maps:** Color-coded matrices plot severity versus probability for each dimension, enabling quick identification of red zones. The guardrails project used a heat map to show ethics risks clustering in the high-impact quadrants.
- **Probability Distribution Charts:** Layered bar charts illustrate expected frequency distributions for different scenarios. The park team shared probability histograms at the town hall to demonstrate how mitigations shifted safety risks toward the “rare” end.
- **Risk Tolerance Boundaries:** Overlay lines define acceptable composite risk zones. During the AI forecasting review, we drew tolerance boundaries that excluded any configuration yielding ethics scores above 3.5, keeping discussions grounded in pre-approved limits.

## Common Pitfalls
- **Dimension blindness:** Failing to include an impacted group or lens (e.g., ignoring accessibility in infrastructure decisions).
- **Severity inflation/deflation:** Overstating or downplaying impacts due to personal bias or advocacy pressure.
- **Probability miscalibration:** Relying on intuition without cross-checking against historical data or external benchmarks.
- **False precision:** Presenting composite scores with excessive decimal places, implying certainty beyond the underlying judgments.
- **Mitigation gaps:** Approving projects with acknowledged risks but no funded or assigned mitigations.

## Advanced Applications
- **Differential Impact Analysis:** Segment scores by stakeholder groups to reveal uneven burdens. The guardrails team produced separate matrices for residents, vendors, and visiting students, uncovering that vendors experienced higher privacy impacts due to stall proximity to cameras.
- **Dynamic Risk Tracking:** Update assessments over time as new information emerges. Post-launch monitoring of the park cleanup includes quarterly soil tests and wildlife surveys, feeding fresh data back into the severity scales.
- **Threshold Adjustment Protocol:** Periodically recalibrate threshold values based on lived experience. After two seasons of using the framework, the council lowered the automatic review trigger from 3.5 to 3.2 when early warning signs were repeatedly validated by field observations.
